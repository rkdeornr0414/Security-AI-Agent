# Security-Agent

# ğŸš¨ Why This Project Exists

Running Clawdbot on a publicly exposed VPS introduces a realistic attack chain.
Default-bound services are continuously scanned and brute-forced by automated botnets. A single misconfiguration or weak credential path can lead to initial access, privilege escalation, and eventual data exposure.

This project was built to break that chain.

# ğŸ¯ Threat Model (MITRE ATT&CK Mapping)

The typical attack flow in a misconfigured VPS environment maps to:

T1190 â€“ Exploit Public-Facing Application 

T1110 â€“ Brute Force

T1078 â€“ Valid Accounts 

T1068 â€“ Privilege Escalation 

T1021 â€“ Remote Services (Lateral Movement)

T1005 â€“ Data from Local System

T1041 â€“ Exfiltration Over C2 Channel

Rather than relying on model behavior alone, this project introduces architectural constraints, layered validation, and strict execution boundaries.

# The philosophy is simple:
Assume exposure. Minimize privilege. Contain damage.

# Diagram


<img width="563" height="389" alt="image" src="https://github.com/user-attachments/assets/b7294d14-49fb-4abe-b97c-b0b3178ab124" />

# Key Principle
No single layer is sufficient. Prompt injection is an unsolved problem in AI security â€” the LLM can always potentially be tricked. That's why the architectural layers (secrets the agent can never access, output filtering, network restrictions) are more important than trying to make the prompt "un-injectable."


# OS
Linux

# Design Philosophy
This is an advisory-only agent. It never executes commands, never writes to the filesystem, and never modifies system state. It observes, analyzes, and guides.
```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DEFENSE-IN-DEPTH LAYERS                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Layer 1: ARCHITECTURAL                                 â”‚
â”‚  â”œâ”€â”€ No subprocess, os.system, or exec calls            â”‚
â”‚  â”œâ”€â”€ No shell access in codebase whatsoever             â”‚
â”‚  â”œâ”€â”€ Agent has zero system privileges                   â”‚
â”‚  â””â”€â”€ Config.allow_command_execution enforced by assert  â”‚
â”‚                                                         â”‚
â”‚  Layer 2: LLM BEHAVIORAL (System Prompt)                â”‚
â”‚  â”œâ”€â”€ Explicit rules against script generation           â”‚
â”‚  â”œâ”€â”€ Mandatory explanation-before-command format        â”‚
â”‚  â”œâ”€â”€ Safe sequencing rules (allow before deny)          â”‚
â”‚  â”œâ”€â”€ Scope boundaries (Linux only, defensive only)      â”‚
â”‚  â””â”€â”€ Required rollback instructions                     â”‚
â”‚                                                         â”‚
â”‚  Layer 3: OUTPUT VALIDATION (safety.py)                 â”‚
â”‚  â”œâ”€â”€ Blocked patterns (curl|bash, rm -rf /, etc.)       â”‚
â”‚  â”œâ”€â”€ Warning injection for dangerous commands           â”‚
â”‚  â”œâ”€â”€ Bulk-script detection                              â”‚
â”‚  â””â”€â”€ Post-LLM filtering before user sees output         â”‚
â”‚                                                         â”‚
â”‚  Layer 4: INPUT VALIDATION                              â”‚
â”‚  â”œâ”€â”€ Prompt injection pattern detection                 â”‚
â”‚  â”œâ”€â”€ Logged but not blocked (system prompt is primary)  â”‚
â”‚  â””â”€â”€ Topic scope enforcement                            â”‚
â”‚                                                         â”‚
â”‚  Layer 5: USER REMAINS EXECUTOR                         â”‚
â”‚  â”œâ”€â”€ User reads, understands, then runs each command    â”‚
â”‚  â”œâ”€â”€ User can verify/question any recommendation        â”‚
â”‚  â”œâ”€â”€ User maintains full audit trail                    â”‚
â”‚  â””â”€â”€ User can stop at any point                         â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Structure

```
Security-AI-Agent/
â”œâ”€â”€ main.py              # Entry point
â”œâ”€â”€ settings.py          # Configuration
â”œâ”€â”€ agent/               # Core agent logic
â”‚   â”œâ”€â”€ chat.py          # Conversation manager
â”‚   â”œâ”€â”€ config.py        # Config loader
â”‚   â”œâ”€â”€ prompt.py        # System prompt builder
â”‚   â””â”€â”€ providers.py     # OpenAI + Anthropic providers
â”œâ”€â”€ knowledge/           # Security knowledge base
â”‚   â”œâ”€â”€ registry.py      # Module registry
â”‚   â”œâ”€â”€ wireguard.py     # WireGuard VPN
â”‚   â”œâ”€â”€ ssh.py           # SSH hardening
â”‚   â”œâ”€â”€ fail2ban.py      # Fail2Ban
â”‚   â”œâ”€â”€ ufw.py           # UFW firewall
â”‚   â””â”€â”€ general.py       # General Linux hardening
â””â”€â”€ modules/             # Utilities
    â””â”€â”€ loader.py        # Auto-loads knowledge modules
```

## Run

### Docker

```bash
docker build -t linux-security-advisor .
docker run -it --rm \
  -e ANTHROPIC_API_KEY=your-key \
  linux-security-advisor
```

### Local

```bash
pip install -r requirements.txt
export ANTHROPIC_API_KEY=your-key
python main.py
```

## Configuration

Edit `settings.py` or use environment variables:

| Variable | Description |
|---|---|
| LSA_PROVIDER | openai or anthropic |
| LSA_MODEL | Model name override |
| OPENAI_API_KEY | OpenAI API key |
| OPENAI_BASE_URL | Custom base URL |
| ANTHROPIC_API_KEY | Anthropic API key |

## Adding Knowledge

Create a new file in `knowledge/`, e.g. `knowledge/docker.py`:

```python
from knowledge import register

register("Docker Security", """
Your knowledge content here.
""")
```

It auto-loads on startup. No other changes needed.
